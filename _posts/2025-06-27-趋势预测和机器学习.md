趋势预测，机器学习线性回归相关的。

## KPI指标定义
KPI（Key Performance Indicator）是关键性能指标，用于衡量系统、网络或业务的质量和性能。项目中的KPI指标体系:
1. 基础网络指标     
2. 业务专项指标         
3. 网络设备指标                  

## 趋势分析和预测

通过线性回归算法分析KPI指标的变化趋势:    
* 预测网络质量指标的走向
* 提前发现潜在的质量问题
* 为容量规划提供数据支撑

### CLinearRegression类用于趋势分析和预测

**杠杆点 (Leverage Point)**  
- **定义**：  
  杠杆点是数据集中因自变量($X$)取值极端而对回归模型产生异常大影响的观测点。  
  - **高杠杆点**会不成比例地影响回归线的斜率和截距。  
  - 通过**帽子值**$h_{ii}$（帽子矩阵$H = X(X^TX)^{-1}X^T$的对角元素）衡量，其中$0 \leq h_{ii} \leq 1$。  
    - 经验法则：当$h_{ii} > \frac{3p}{n}$（$p$为预测变量数，$n$为样本量）时标记为高杠杆点。  

- **影响**：  
  - 若与趋势一致（如$X$极端但有效），可提升模型拟合。  
  - 若偏离趋势（异常值），会导致回归线扭曲。  

**过原点回归 (Regression Through the Origin (RTO))**  
- **定义**：  
  强制截距项($B_0$)为零的回归模型：  
  $$  
  Y_i = B_1 X_i + \epsilon_i  
  $$  
  - 假设真实关系通过$(0,0)$点。  

- **适用场景**：  
  - 理论依据明确时。  
  - 当$X=0$时$Y$必为零时（如生产投入与产出）。  

- **与带截距模型的差异**：  

  | **对比维度**       | **带截距模型**               | **过原点回归**               |  
  |--------------------|-----------------------------|-----------------------------|  
  | **方程**           | $Y_i = B_0 + B_1 X_i + \epsilon_i$ | $Y_i = B_1 X_i + \epsilon_i$ |  
  | **斜率($B_1$)**    | $\hat{B_1} = \frac{S_{XY}}{S_{XX}}$ | $\hat{B}_1 = \frac{\sum X_i Y_i}{\sum X_i^2}$ |  
  | **R²解释**         | 模型间可比                   | 人为偏高，不可比             |  

**杠杆点与RTO的关联**  
- **数据增强法**：  
  为验证$B_0=0$是否合理，向原始数据添加**构造点**$(X_{n+1}, Y_{n+1}) = (n^* \bar{X}, n^* \bar{Y})$，其中：  
  $$  
  n^* = \frac{n}{\sqrt{n+1} - 1}  
  $$  
  - **目的**：通过该点的高杠杆效应强制回归线过原点。
  - **Define the Augmented Dataset**
    - Original dataset: $(X_1, Y_1), (X_2, Y_2), \dots, (X_n, Y_n)$.  
    - Augmented point: $(X_{n+1}, Y_{n+1}) = (n^* \bar{X}, n^* \bar{Y})$.  
    - New means after augmentation:  $$
  \bar{X}_{n+1} = \frac{n \bar{X} + n^* \bar{X}}{n+1} = \bar{X} \left( \frac{n + n^*}{n+1} \right), \\
  \quad \bar{Y}_{n+1} = \bar{Y} \left( \frac{n + n^*}{n+1} \right).$$
    - Then fitting the full model to the augmented data set is equivalent to forcing the original regression through the origin. This follows from the easily verified identities $$\sum_{i=1}^{n+1} (X_i - \bar{X}_{n+1})(Y_i - \bar{Y}_{n+1}) = \sum_{i=1}^n X_i Y_i \\
    \sum_{i=1}^{n+1} (X_i - \bar{X}_{n+1})^2 = \sum_{i=1}^n X_i^2 $$

  
  - **杠杆值计算**：  
    $$  
    h_{n+1} = \frac{1}{n+1}\left[1 + \frac{n^2 \bar{X}^2}{\sum X_i^2}\right]  
    $$  
    若$h_{n+1} > \frac{3p}{n}$，则支持无截距模型。  

- **假设检验**：  
  - **原假设($H_0$)**：$B_0 = 0$（无需截距）。  
  - **检验统计量**：  
    $$  
    t_0 = \frac{\hat{B}_0}{\text{SE}(\hat{B}_0)}  
    $$  
    当$|t_0| > t_{\alpha/2, n-p-1}$时拒绝$H_0$。  


**实例**       
- 添加$(n^* \bar{X}, n^* \bar{Y})$后得$h_{101} = 0.836 > 0.237$（$\frac{3 \times 7}{100}$），证实截距必要性。  
- 带截距模型（MSE $= 10965$）显著优于RTO模型（MSE $= 383983$）。  

**结论**：需联合杠杆分析与假设检验判断是否采用过原点回归。  

带截距项的线性回归模型：  
$$  
Y = \beta_0 + X\beta_1  
$$

$\hat{\beta}_1$的最小二乘回归值是

$$\hat{\beta}_1 = \frac{S_{xy}}{S_{xx}} = \frac{\sum_1^n (y_i - \bar{y} ) (x_i - \bar{x})}{\sum_1^n (x_i - \bar{x})^2} \\
\hat{\beta}_0 = \bar{Y} - \bar{X}\hat{\beta}_1.$$

### 方差分析


**零模型 vs. 拟合模型**
- **零模型（仅截距）：**  
  $Y = \beta_0 + \epsilon$
  - 仅包含截距项（$\beta_0$，$Y$ 的均值）。  
  - 假设 $Y$ 与任何预测变量 $X$ 之间*没有关系*。  

- **拟合模型（回归）：**  
  $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p + \epsilon$
  - 包含预测变量（$X_1, X_2, \dots, X_p$）。  
  - 检验是否至少有一个 $\beta_i \neq 0$（即预测变量是否增加解释力）。  

---

**检验工作原理**        
ANOVA 中的 **F 检验**通过分析方差来比较这些模型：  
- **零假设（$H_0$）：** 所有预测变量系数都为零（$\beta_1 = \beta_2 = \dots = \beta_p = 0$）。  
  - 意味着零模型与你的拟合模型一样好。  
- **备择假设（$H_1$）：** 至少有一个 $\beta_i \neq 0$。  
  - 意味着你的带预测变量的模型更好地拟合数据。  

**ANOVA 表中的关键组成部分：**  
| 来源       | 平方和 (SS) | 均方 (MS) | F 统计量 | p 值 |
|--------------|---------------------|------------------|-------------|---------|
| **回归** | SSR（已解释）     | MSR = SSR / df   | F = MSR / MSE | p       |
| **残差**   | SSE（未解释）   | MSE = SSE / df   |      -       |    -     |
| **和** | SST | -  | - | - |

- **F 统计量**：已解释方差（MSR）与未解释方差（MSE）的比值。  
  - 大的 $F$ = 预测变量解释的方差比随机噪声更多。  
- **p 值**：如果 $H_0$ 为真时观察到这样的 $F$ 统计量的概率。  
  - $p < 0.05$ → 拒绝 $H_0$；你的模型比零模型更好。

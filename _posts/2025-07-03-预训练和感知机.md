Perceptron Learning (感知机学习), BERT，预训练。

## 考虑使用MLP得到embedding的原因

当输入不是文本token（如数值patch、流量特征等），无法直接查表embedding，这时用MLP（多层感知机）把原始数值特征转成高维向量，作为BERT的输入。

## Neuron

In the early 1940’s Warren McCulloch, a neurophysiologist, teamed up with logician Walter Pitts to create a model of how brains work. It was a simple linear model that produced a positive or negative output, given a set of inputs and weights.

## Perceptron Learning for Binary classification, The Simplest Artificial neural network

It was only a decade later that Frank Rosenblatt extended this model, and created an algorithm that could learn the weights in order to generate an output. The famous Perceptron Learning Algorithm was originally proposed by Frank Rosenblatt in 1943, later refined and carefully analyzed by Minsky and Papert in 1969. This is a follow-up post of my previous posts on the McCulloch-Pitts neuron model and the Perceptron model.

The perceptron model is a more general computational model than McCulloch-Pitts neuron. It takes an input, aggregates it (weighted sum) and returns 1 only if the aggregated sum is more than some threshold else returns 0 (大于某个阈值返回1，否则0), which is called **step function or threshold function**. Rewriting the threshold as shown above and making it a constant input with a variable weight, we would end up with something like the following:

![Perceptron]({{ "assets/images/2025-07-03/1_Fyapb-JRFJ-VtnLYLLXCwg.jpg" | relative_url }})

In fact, In modern implementations, we can use other activation functions like the sigmoid function:

$$\sigma(z) = \frac{1}{1 + \exp(-z)}$$

The perceptron model is a more general computational model than McCulloch-Pitts neuron. It takes an input, aggregates it (weighted sum) and returns 1 only if the aggregated sum is more than some threshold else returns 0. Rewriting the threshold as shown above and making it a constant input with a variable weight ($i = 0$), we would end up with something like the following:

![Perceptron]({{ "assets/images/2025-07-03/1_gKFs7YU44vJFiS2rF3-bpg.jpg" | relative_url }})

A single perceptron can only be used to implement linearly separable functions (binary classification). It takes both real and boolean inputs and associates a set of weights to them, along with a bias (the threshold thing I mentioned above). We learn the weights, we get the function. Let's use a perceptron to learn an OR function.

What’s going on above is that we defined a few conditions (the weighted sum has to be more than or equal to 0 when the output is 1) based on the OR function output for various sets of inputs, we solved for weights based on those conditions and we got one of the possible lines that perfectly separates positive inputs from those of negative.

![Perceptron]({{ "assets/images/2025-07-03/1_C5LeL8JDfoGbkUg0cu1M-w.jpg" | relative_url }})

To get the best model, The loss function is a crucial concept in machine learning that quantifies the error or discrepancy between the model's predictions and the actual target values.

Its purpose is to penalize the model for making incorrect or inaccurate predictions, which guides the learning algorithm (for example, gradient descent) to adjust the model's parameters in a way that minimizes this error and improves performance.

In a binary classification task, the model may adopt the hinge loss function to penalize misclassifications by incurring an additional cost for incorrect predictions:

$$L(y, h(x)) = \max (0, 1 - y \cdot h(x)) \\
\text{(h(x): prediction label, y: true label)}$$

Our goal is to find the w vector that can perfectly classify positive inputs and negative inputs in our data. 

We initialize w with some random vector. We then iterate over all the examples in the data, ($P \cup N$) both positive and negative examples. Now if an input x belongs to P, ideally what should the dot product $w \cdot x$ be? I’d say $w \cdot x \geq 0$ because that’s the only thing what our perceptron wants at the end of the day so let's give it that. And if x belongs to N, the dot product MUST be less than 0. 

Why Would The Specified Update Rule Work? We have already established that when x belongs to P, we want $w \cdot x \geq 0$, basic perceptron rule. What we also mean by that is that when x belongs to P, the angle between w and x should be less than 90 because the cosine of the angle is proportional to the dot product. So whatever the w vector may be, as long as it makes an angle less than 90 degrees with the positive example data vectors (x E P) and an angle more than 90 degrees with the negative example data vectors (x E N), we are cool. So ideally, it should look something like this:

![Perceptron]({{ "assets/images/2025-07-03/1_D09EzbR-sGbX-qv2jcEPhw.jpg" | relative_url }})

So we now strongly believe that the angle between w and x should be less than 90 when x belongs to P class and the angle between them should be more than 90 when x belongs to N class. Pause and convince yourself that the above statements are true and you indeed believe them. Here’s why the update works: when we are adding x to w, which we do when x belongs to P and w.x < 0 (Case 1, left one), we are essentially increasing the cos(alpha) value, which means, we are decreasing the alpha value, the angle between w and x, which is what we desire. And the similar intuition works for the case when x belongs to N and w.x ≥ 0 (Case 2, right one).

![Perceptron]({{ "assets/images/2025-07-03/1_Ny1n6xH8g2JR2XVhcGRVvA.jpg" | relative_url }})

Let's go to the complete algorithm:
 
![Perceptron]({{ "assets/images/2025-07-03/1_PbJBdf-WxR0Dd0xHvEoh4A.jpg" | relative_url }})

## Multilayer Perceptron (MLP)

The Multilayer Perceptron was developed to tackle this limitation. It is a neural network where the mapping between inputs and output is non-linear.

A Multilayer Perceptron has input and output layers, and one or more hidden layers with many neurons stacked together. And while in the Perceptron the neuron must have an activation function that imposes a threshold, like ReLU or sigmoid, neurons in a Multilayer Perceptron can use any arbitrary activation function.
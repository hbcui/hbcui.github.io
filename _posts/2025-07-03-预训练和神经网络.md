Perceptron Learning (感知器学习), BERT，预训练。

## Perceptron Learning, The Simplest Artificial neural network

The famous Perceptron Learning Algorithm was originally proposed by Frank Rosenblatt in 1943, later refined and carefully analyzed by Minsky and Papert in 1969. This is a follow-up post of my previous posts on the McCulloch-Pitts neuron model and the Perceptron model.

The perceptron model is a more general computational model than McCulloch-Pitts neuron. It takes an input, aggregates it (weighted sum) and returns 1 only if the aggregated sum is more than some threshold else returns 0 (大于某个阈值返回1，否则0). Rewriting the threshold as shown above and making it a constant input with a variable weight, we would end up with something like the following:

![Perceptron]({{ "assets/images/2025-07-03/1_Fyapb-JRFJ-VtnLYLLXCwg.jpg" | relative_url }})

The perceptron model is a more general computational model than McCulloch-Pitts neuron. It takes an input, aggregates it (weighted sum) and returns 1 only if the aggregated sum is more than some threshold else returns 0. Rewriting the threshold as shown above and making it a constant input with a variable weight ($i = 0$), we would end up with something like the following:

![Perceptron]({{ "assets/images/2025-07-03/1_gKFs7YU44vJFiS2rF3-bpg.jpg" | relative_url }})
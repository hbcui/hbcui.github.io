在阶段1和阶段2的基础上，继续做One click相关的修改。

### 阶段2

#### 统计输出路径

所有统计输出csv总显示测试路径，不是真实的数据路径。

```
app_name,flow_nums,avg_flow_len,avg_packet_num
data_source: 20:/data1/traffic_data; 97:/data1/traffic_data,,,
com.jinxin.namibox.csv,425,1077717.88,727.38
com.mofang_app.csv,2022,959112.21,645.04
com.huozai189.huosuapp.csv,456,4444609.03,2876.7
```

修改`stage2_traffic_corpus_statistic_single_node.py`。更新统计对象。

```python
    # 新增：统计协议分布
    # 原始代码保留
    # 新增：协议统计
    if 'protocol' in df.columns:
        protocol_counts = df['protocol'].value_counts().to_dict()
        print(f"Protocol distribution for {app_name}: {protocol_counts}")
```

应该传参而不是直接写入路径。

```python
def entrance_statistic():
    .................
    # 保存 app_name 相关记录
    merge_dicts_to_csv(
        dict1 = flow_nums_app_count_dict,
        dict2 = avg_flow_len_app_count_dict,
        dict3 = avg_packet_num_app_count_dict,
        file_name = f'{dir_csv}/统计/{datetime_str}/app_count.csv',
        field_str = 'app_name',
        data_source='20:/data1/traffic_data; 97:/data1/traffic_data')

    # 保存app_name+app_version相关记录
    merge_dicts_to_csv(
        dict1=flow_nums_app_ver_count_dict,
        dict2=avg_flow_len_app_ver_count_dict,
        dict3=avg_packet_num_app_ver_count_dict,
        file_name=f'{dir_csv}/统计/{datetime_str}/app_version_count.csv',
        field_str='app_name+app_version',
        data_source='20:/data1/traffic_data; 97:/data1/traffic_data')
    .................
```

像这样修改。

```python
def entrance_statistic():
    .................
```

另外，统计输出路径下按照时间戳产生很多中间的没有的空文件夹。需要修改，把输出文件直接放到统计路径下面。

```
[10354278@LIN-82D624853E4 hbcui.github.io]$ tree /home/10354278/文档/Assignments/corpus_path/data_processed/pcap/统计
/home/10354278/文档/Assignments/corpus_path/data_processed/pcap/统计
├── 2025-07-23_15:43:51
│   ├── app_count.csv
│   ├── app_version_count.csv
│   ├── avg_flow_len_app_count_dict.csv
│   ├── avg_flow_len_app_ver_count_dict.csv
│   ├── avg_packet_num_app_count_dict.csv
│   ├── avg_packet_num_app_ver_count_dict.csv
│   ├── flow_nums_app_count_dict.csv
│   └── flow_nums_app_ver_count_dict.csv
├── 2025-07-23_16:10:32
└── 2025-07-23_16:11:00
```

### 阶段3

在修改完阶段1和阶段2的基础上，下面修改`run.sh`的参数。和上面一样，`hdfs`路径暂时不用动，其他的换成你的路径。

```bash
    "one_click")
        echo "Running one_click: all stages..."
        # If in MacOS, use python3; if in Linux, use python, if in Windows, use python.
        python one_click.py \
        --hdfs_base_path '/data1/scrawl/pcap' \
        --local_base_path '/home/10354278/下载/pcap' \
        --target_base_path '/home/10354278/文档/Assignments/corpus_path/data_processed/target' \
        --save_path_pcap '/home/10354278/文档/Assignments/corpus_path/data_processed/pcap' \
        --save_path_csv '/home/10354278/文档/Assignments/corpus_path/data_processed/csv' \
        ;;
    *)
```

下面修改`./one_click.py`。和阶段一一样，注释掉hdfs下载，直接用本地数据。

```bash
def main()
    ..........
    ##### step 0: 流量数据下载
    # 创建下载器实例
    # downloader = HDFSDownloader()
    # 多进程下载文件
    # downloader.download_files(args.hdfs_base_path, args.local_base_path)
    
    ##### step 1: 流量数据划分
    
    # 获取时间戳作为数据集版本标识
    datetime_str = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')
    # 文件划分 & 移动
    traffic_data_split(args.local_base_path, args.target_base_path, datetime_str)
```
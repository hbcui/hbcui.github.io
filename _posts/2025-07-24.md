# stage2-1click
阶段2和一键二阶段合一这2部分相关的修改。

### 阶段2

#### 传参

```python
--save_path_pcap '/home/10354278/文档/Assignments/corpus_path/data_processed/pcap' 
```

所有统计输出csv总显示测试路径，不是真实的数据路径。

```
app_name,flow_nums,avg_flow_len,avg_packet_num
data_source: 20:/data1/traffic_data; 97:/data1/traffic_data,,,
com.jinxin.namibox.csv,425,1077717.88,727.38
com.mofang_app.csv,2022,959112.21,645.04
com.huozai189.huosuapp.csv,456,4444609.03,2876.7
```

修改`stage2_traffic_corpus_statistic_single_node.py`。应该传参而不是直接写入路径。

```python
def entrance_statistic():
    .................
    # 保存 app_name 相关记录
    merge_dicts_to_csv(
        dict1 = flow_nums_app_count_dict,
        dict2 = avg_flow_len_app_count_dict,
        dict3 = avg_packet_num_app_count_dict,
        file_name = f'{dir_csv}/统计/{datetime_str}/app_count.csv',
        field_str = 'app_name',
        data_source='20:/data1/traffic_data; 97:/data1/traffic_data')

    # 保存app_name+app_version相关记录
    merge_dicts_to_csv(
        dict1=flow_nums_app_ver_count_dict,
        dict2=avg_flow_len_app_ver_count_dict,
        dict3=avg_packet_num_app_ver_count_dict,
        file_name=f'{dir_csv}/统计/{datetime_str}/app_version_count.csv',
        field_str='app_name+app_version',
        data_source='20:/data1/traffic_data; 97:/data1/traffic_data')

    # 保存 app_name 相关记录
    # merge_dicts_to_csv(
    #     dict1 = flow_nums_app_count_dict,
    #     dict2 = avg_flow_len_app_count_dict,
    #     dict3 = avg_packet_num_app_count_dict,
    #     file_name = f'{dir_csv}/统计/{datetime_str}/app_count.csv',
    #     field_str = 'app_name',
    #     data_source = dir_csv  # 这里用变量传参
    # )
    # 新增：直接输出到统计/
    merge_dicts_to_csv(
        dict1 = flow_nums_app_count_dict,
        dict2 = avg_flow_len_app_count_dict,
        dict3 = avg_packet_num_app_count_dict,
        file_name = f'{dir_csv}/统计/app_count.csv',
        field_str = 'app_name',
        data_source = dir_csv  # 这里用变量传参
    )

    # 保存app_name+app_version相关记录
    # merge_dicts_to_csv(
    #     dict1=flow_nums_app_ver_count_dict,
    #     dict2=avg_flow_len_app_ver_count_dict,
    #     dict3=avg_packet_num_app_ver_count_dict,
    #     file_name=f'{dir_csv}/统计/{datetime_str}/app_version_count.csv',
    #     field_str='app_name+app_version',
    #     data_source = dir_csv  # 这里用变量传参
    # )
    # 新增：直接输出到统计/
    merge_dicts_to_csv(
        dict1=flow_nums_app_ver_count_dict,
        dict2=avg_flow_len_app_ver_count_dict,
        dict3=avg_packet_num_app_ver_count_dict,
        file_name=f'{dir_csv}/统计/app_version_count.csv',
        field_str='app_name+app_version',
        data_source = dir_csv  # 这里用变量传参
    )
```

现在，csv第二行现在可以显示传参路径。

```
app_name,flow_nums,avg_flow_len,avg_packet_num
data_source: /home/10354278/文档/Assignments/corpus_path/data_processed/pcap,,,
```

#### 输出路径

另外，统计输出路径下按照时间戳产生很多中间的没有的空文件夹。需要修改，把输出文件直接放到统计路径下面。

```
[10354278@LIN-82D624853E4 hbcui.github.io]$ tree /home/10354278/文档/Assignments/corpus_path/data_processed/pcap/统计
/home/10354278/文档/Assignments/corpus_path/data_processed/pcap/统计
├── 2025-07-23_15:43:51
│   ├── app_count.csv
│   ├── app_version_count.csv
│   ├── avg_flow_len_app_count_dict.csv
│   ├── avg_flow_len_app_ver_count_dict.csv
│   ├── avg_packet_num_app_count_dict.csv
│   ├── avg_packet_num_app_ver_count_dict.csv
│   ├── flow_nums_app_count_dict.csv
│   └── flow_nums_app_ver_count_dict.csv
├── 2025-07-23_16:10:32
└── 2025-07-23_16:11:00
```

像这样修改。只把原路径代码行注释掉。

```python
    # 保存流数为json文件
    # save_dict_to_csv(flow_nums_app_count_dict, f'{dir_csv}/统计/{datetime_str}/flow_nums_app_count_dict.csv')
    # save_dict_to_csv(flow_nums_app_ver_count_dict, f'{dir_csv}/统计/{datetime_str}/flow_nums_app_ver_count_dict.csv')
    # 新增：直接输出到统计/
    save_dict_to_csv(flow_nums_app_count_dict, f'{dir_csv}/统计/flow_nums_app_count_dict.csv')
    save_dict_to_csv(flow_nums_app_ver_count_dict, f'{dir_csv}/统计/flow_nums_app_ver_count_dict.csv')

    # 计算每种app平均流长度： flow_len / flow_nums
    avg_flow_len_app_count_dict = {}
    for key in flow_len_app_count_dict.keys():
        if key in flow_nums_app_count_dict.keys():
            avg_flow_len_app_count_dict[key] = \
                round(flow_len_app_count_dict[key] / flow_nums_app_count_dict[key], 2)
    # save_dict_to_csv(avg_flow_len_app_count_dict, f'{dir_csv}/统计/{datetime_str}/avg_flow_len_app_count_dict.csv')
    # 新增：直接输出到统计/
    save_dict_to_csv(avg_flow_len_app_count_dict, f'{dir_csv}/统计/avg_flow_len_app_count_dict.csv')

    # 计算平均每种app，不同版本的平均流长度app_name + app_version : sum_flow_len/flow_nums
    avg_flow_len_app_ver_count_dict = {}
    for key in flow_len_app_ver_count_dict.keys():
        if key in flow_nums_app_ver_count_dict.keys():
            avg_flow_len_app_ver_count_dict[key] = \
                round(flow_len_app_ver_count_dict[key] / flow_nums_app_ver_count_dict[key], 2)
    # save_dict_to_csv(avg_flow_len_app_ver_count_dict, f'{dir_csv}/统计/{datetime_str}/avg_flow_len_app_ver_count_dict.csv')
    # 新增：直接输出到统计/
    save_dict_to_csv(avg_flow_len_app_ver_count_dict, f'{dir_csv}/统计/avg_flow_len_app_ver_count_dict.csv')

    # 计算平均每种app平均包个数 app_name : sum_packet_num/flow_nums
    avg_packet_num_app_count_dict = {}
    for key in packet_num_app_count_dict.keys():
        if key in flow_nums_app_count_dict.keys():
            avg_packet_num_app_count_dict[key] = \
                round(packet_num_app_count_dict[key] / flow_nums_app_count_dict[key], 2)
    # save_dict_to_csv(avg_packet_num_app_count_dict, f'{dir_csv}/统计/{datetime_str}/avg_packet_num_app_count_dict.csv')
    # 新增：直接输出到统计/
    save_dict_to_csv(avg_packet_num_app_count_dict, f'{dir_csv}/统计/avg_packet_num_app_count_dict.csv')

    # 计算平均每种app，不同版本的平均流长度app_name + app_version : sum_packet_num/flow_nums
    avg_packet_num_app_ver_count_dict = {}
    for key in packet_num_app_ver_count_dict.keys():
        if key in flow_nums_app_ver_count_dict.keys():
            avg_packet_num_app_ver_count_dict[key] = \
                round(packet_num_app_ver_count_dict[key] / flow_nums_app_ver_count_dict[key], 2)
    # save_dict_to_csv(avg_packet_num_app_ver_count_dict, f'{dir_csv}/统计/{datetime_str}/avg_packet_num_app_ver_count_dict.csv')
    # 新增：直接输出到统计/
    save_dict_to_csv(avg_packet_num_app_ver_count_dict, f'{dir_csv}/统计/avg_packet_num_app_ver_count_dict.csv')
```

现在输出统计直接到路径下。

```
[10354278@LIN-82D624853E4 hbcui.github.io]$ tree /home/10354278/文档/Assignments/corpus_path/data_processed/pcap/统计
/home/10354278/文档/Assignments/corpus_path/data_processed/pcap/统计
├── app_count.csv
├── app_version_count.csv
├── avg_flow_len_app_count_dict.csv
├── avg_flow_len_app_ver_count_dict.csv
├── avg_packet_num_app_count_dict.csv
├── avg_packet_num_app_ver_count_dict.csv
├── flow_nums_app_count_dict.csv
└── flow_nums_app_ver_count_dict.csv
```

#### 增加统计指标的判断条件

统计`app_version`, `flow_len`出现的报错。实际上，原因在不是所有输出的统计文件都要包含这些列，也就是说当判断只有包含这些列的时候才应该处理，而不是每个文件都处理。           
我发现这个问题出现是因为之前留下的代码错误地产生来自大模型`# Started by AICoder, pid:qb4a0jba34f1579143c60a796023431f2127e34d`。

```
Traceback (most recent call last):
  File "/usr/lib64/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/usr/lib64/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/10354278/文档/Assignments/corpus_path/stage2_traffic_corpus_statistic_single_node.py", line 38, in process_csv
    app_version_counts = df['app_version'].value_counts().to_dict()
  File "/home/10354278/文档/Assignments/corpus/.venv/lib64/python3.8/site-packages/pandas/core/frame.py", line 3761, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/10354278/文档/Assignments/corpus/.venv/lib64/python3.8/site-packages/pandas/core/indexes/base.py", line 3655, in get_loc
    raise KeyError(key) from err
KeyError: 'app_version'
```

```
Traceback (most recent call last):
  File "/usr/lib64/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/usr/lib64/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/10354278/文档/Assignments/corpus_path/stage2_traffic_corpus_statistic_single_node.py", line 55, in process_csv
    df['flow_len'] = pd.to_numeric(df['flow_len'], errors='coerce')
  File "/home/10354278/文档/Assignments/corpus/.venv/lib64/python3.8/site-packages/pandas/core/frame.py", line 3761, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/10354278/文档/Assignments/corpus/.venv/lib64/python3.8/site-packages/pandas/core/indexes/base.py", line 3655, in get_loc
    raise KeyError(key) from err
KeyError: 'flow_len'
```

```python
def process_csv(csv_file):
    # 初始化统计字典
    flow_nums_app_count_dict = {}
    flow_nums_app_ver_count_dict = {}
    flow_len_app_count_dict = {}
    flow_len_app_ver_count_dict = {}
    packet_num_app_count_dict = {}
    packet_num_app_ver_count_dict = {}

    app_name = os.path.basename(csv_file)
    try:
        df = pd.read_csv(csv_file)
    except Exception as e:
        print(f"无法读取文件 {csv_file}: {e}")
        return flow_nums_app_count_dict, flow_nums_app_ver_count_dict, flow_len_app_count_dict, \
            flow_len_app_ver_count_dict, packet_num_app_count_dict, packet_num_app_ver_count_dict

    # 1 & 2、统计行数
    line_count = len(df)
    flow_nums_app_count_dict[app_name] = flow_nums_app_count_dict.get(app_name, 0) + line_count

    # 3、统计不同版本的记录条数
    if 'app_version' in df.columns:
        app_version_counts = df['app_version'].value_counts().to_dict()
        for app_version, record_cnt in app_version_counts.items():
            dict_key = f"{app_name}+{app_version}"
            flow_nums_app_ver_count_dict[dict_key] = flow_nums_app_ver_count_dict.get(dict_key, 0) + record_cnt
    else:
        # 没有app_version列，跳过
        pass
    
    # 新增：统计协议分布
    # 原始代码保留
    # 新增：协议统计
    if 'protocol' in df.columns:
        protocol_counts = df['protocol'].value_counts().to_dict()
        print(f"Protocol distribution for {app_name}: {protocol_counts}")

    # 4、统计流长度
    if 'flow_len' in df.columns:
        df['flow_len'] = pd.to_numeric(df['flow_len'], errors='coerce')
        sum_flow_len = df['flow_len'].sum()
        flow_len_app_count_dict[app_name] = flow_len_app_count_dict.get(app_name, 0) + sum_flow_len

        # 5、统计每个版本的流长度
        if 'app_version' in df.columns:
            result = df.groupby('app_version')['flow_len'].sum().to_dict()
            for app_version, sum_flow_len in result.items():
                dict_key = f"{app_name}+{app_version}"
                flow_len_app_ver_count_dict[dict_key] = flow_len_app_ver_count_dict.get(dict_key, 0) + sum_flow_len
    else:
        # 没有flow_len列，跳过
        pass

    # 6、统计包个数
    if 'packet_num' in df.columns:
        df['packet_num'] = pd.to_numeric(df['packet_num'], errors='coerce')
        sum_packet_num = df['packet_num'].sum()
        packet_num_app_count_dict[app_name] = packet_num_app_count_dict.get(app_name, 0) + sum_packet_num

        # 7、统计每个版本的包个数
        if 'app_version' in df.columns:
            result = df.groupby('app_version')['packet_num'].sum().to_dict()
            for app_version, sum_packet_num in result.items():
                dict_key = f"{app_name}+{app_version}"
                packet_num_app_ver_count_dict[dict_key] = packet_num_app_ver_count_dict.get(dict_key, 0) + sum_packet_num
    else:
        # 没有packet_num列，跳过
        pass

    return flow_nums_app_count_dict, flow_nums_app_ver_count_dict, flow_len_app_count_dict, \
        flow_len_app_ver_count_dict, packet_num_app_count_dict, packet_num_app_ver_count_dict
```

### 一键：2个阶段合1步

#### 传参

在修改完阶段1和阶段2的基础上，下面修改`run.sh`的参数。和上面一样，`hdfs`路径暂时不用动，其他的换成你的路径。

```bash
    "one_click")
        echo "Running one_click: all stages..."
        # If in MacOS, use python3; if in Linux, use python, if in Windows, use python.
        python one_click.py \
        --hdfs_base_path '/data1/scrawl/pcap' \
        --local_base_path '/home/10354278/下载/pcap' \
        --target_base_path '/home/10354278/文档/Assignments/corpus_path/data_processed/target' \
        --save_path_pcap '/home/10354278/文档/Assignments/corpus_path/data_processed/pcap' \
        --save_path_csv '/home/10354278/文档/Assignments/corpus_path/data_processed/csv' \
        ;;
    *)
```

下面修改`./one_click.py`。和阶段一一样，注释掉hdfs下载，直接用本地数据。

```bash
def main()
    ..........
    ##### step 0: 流量数据下载
    # 创建下载器实例
    # downloader = HDFSDownloader()
    # 多进程下载文件
    # downloader.download_files(args.hdfs_base_path, args.local_base_path)
    
    ##### step 1: 流量数据划分
    
    # 获取时间戳作为数据集版本标识
    datetime_str = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')
    # 文件划分 & 移动
    traffic_data_split(args.local_base_path, args.target_base_path, datetime_str)
```

#### pcap

pcap路径下面训练、验证、测试每次的结果都被保留，导致文件越来越多。下面需要每次运行前清空这些路径。

```bash
[10354278@LIN-82D624853E4 ~]$ tree /home/10354278/文档/Assignments/corpus_path/data_processed/pcap/训练
/home/10354278/文档/Assignments/corpus_path/data_processed/pcap/训练
├── 2025-07-21_09:17:26
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
├── 2025-07-21_09:27:00
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
├── 2025-07-21_09:55:21
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
├── 2025-07-21_10:00:12
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
├── 2025-07-21_14:56:02
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
│   ..........
├── 2025-07-23_16:11:00
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
├── 2025-07-23_17:03:18
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
├── 2025-07-23_17:19:17
├── 2025-07-23_17:35:22
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
├── 2025-07-24_09:27:14
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
├── 2025-07-24_09:38:59
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
├── 2025-07-24_09:51:15
│   ├── com.taobao.csv
│   ├── email.csv
│   ├── qq.csv
│   └── WeChat.csv
└── 2025-07-24_10:09:53
    ├── com.taobao.csv
    ├── email.csv
    ├── qq.csv
    └── WeChat.csv

40 directories, 1203 files
```

在每次运行前，自动清空训练、验证、评测等输出目录下的所有内容。

```python
    # os.makedirs(args.save_path_csv, exist_ok=True)
    base = args.save_path_pcap
    clear_dirs([
        os.path.join(base, '训练'),
        os.path.join(base, '验证'),
        os.path.join(base, '评测')
    ])
```

处理之后的路径，只完整保留本次的结果足够了。

```
(.venv) [10354278@LIN-82D624853E4 corpus_path]$ tree /home/10354278/文档/Assignments/corpus_path/data_processed/pcap/训练
/home/10354278/文档/Assignments/corpus_path/data_processed/pcap/训练
└── 2025-07-24_10:25:49
    ├── com.taobao.csv
    ├── email.csv
    ├── qq.csv
    └── WeChat.csv

1 directory, 4 files
```